{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/saturn_logo.png\" width=\"300\" />\n",
    "\n",
    "# Introduction to PyTorch with Dask\n",
    "\n",
    "## Welcome!\n",
    "\n",
    "This workshop is meant to help users of PyTorch for deep learning get familiar with some useful concepts in Dask that can make your work faster and easier. We will specifically be looking at Computer Vision tasks for our examples, but Pytorch and Dask can be used for many other kinds of deep learning cases.\n",
    "\n",
    "After this workshop, you will know:\n",
    "* Basics of how Dask works\n",
    "* How to run inference with a pretrained model on Dask cluster\n",
    "* How to run transfer learning on Dask cluster\n",
    "\n",
    "\n",
    "#### _Wait!_\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/tHy9Qsv4svHXt7Eiq5/giphy.gif\" alt=\"wait\" style=\"width: 200px;\"/>\n",
    "\n",
    "#### If you are _**not**_ reading this from inside Jupyter Lab in Saturn Cloud, check out the [README.md](README.md) to set up your account and servers.\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "## Saturn Cloud concepts\n",
    "\n",
    "### Projects\n",
    "\n",
    "A \"Project\" is where all the work done in Saturn Cloud resides. Each user can have multiple projects, and these projects can be shared between users. The services associated with each project are called \"Resources\" and they are organized in the following manner:\n",
    "\n",
    "```\n",
    "└── Project\n",
    "    ├── Jupyter Server (*)\n",
    "    │   └── Dask Cluster\n",
    "    ├── Deployment\n",
    "    │   └── Dask Cluster\n",
    "```\n",
    "\n",
    "(*) Every Project has a Jupyter Server, while Dask Clusters and Deployments are optional.\n",
    "\n",
    "### Images\n",
    "\n",
    "An \"Image\" is a Docker image that contains a Python environment to be attached to various Resources. A Project is set to use one Image, and all Resources in that Project will utilize the same Image.\n",
    "\n",
    "Saturn Cloud includes pre-built images for users to get up and running quickly. Users can create custom images by navigating to the \"Images\" tab from the Saturn Cloud UI.\n",
    "\n",
    "### Jupyter Server\n",
    "\n",
    "This resource runs the Jupyter Notebook and Jupyter Lab interfaces. Most time will likely be spent \"inside\" one of these Jupyter interfaces. \n",
    "\n",
    "### Dask Cluster\n",
    "\n",
    "A Dask Cluster can be attached to a Jupyter Server to scale out work. Clusters are composed of a scheduler instance and any number of worker instances. Clusters can be created and started/stopped from the Saturn Cloud UI. The [dask-saturn](https://github.com/saturncloud/dask-saturn) package is the interface for working with Dask Clusters in a notebook or script within a Jupyter Server, and can also be used to start, stop, or resize the cluster.\n",
    "\n",
    "### Deployment\n",
    "\n",
    "A \"Deployment\" is a resource that is created to serve an always-on or scheduled workload such as serving a machine learning model, hosting a dashboard via a web app, or an ETL job. It utilizes the same project Image and code from the Jupyter Server, and can optional have its own Dask cluster assigned to it.\n",
    "\n",
    "Deployments will not be covered in this workshop.\n",
    "\n",
    "### Code and data files\n",
    "\n",
    "The filesystem of a Jupyter Server is maintained on persistent volumes, so any code or files created/uploaded will remain there after shutting down the server. \n",
    "\n",
    "However, all files are not sent to associated Dask cluster workers or Deployments because those are different machines with their own filesystems. \n",
    "\n",
    "**Code**: Code maintained in the `/home/jovyan/project` folder or through the Repositories feature will be sent to the resources when they are turned on. \n",
    "\n",
    "**Data files**: Data files should be managed outside of Saturn Cloud in systems such as S3 or a database. This ensures each worker in a Dask cluster has access to the data.\n",
    "\n",
    "### Advanced settings\n",
    "\n",
    "Advanced settings for Projects include Environment Variables and Start Scripts. These will not be covered in the workshop, but more information can be found in the [Saturn Cloud docs](https://www.saturncloud.io/docs/getting-started/spinning/jupyter/#advanced-settings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Hello world\n",
    "\n",
    "Run the following cell to ensure your Dask cluster is up and running (if it is not yet started, it may take a few minutes to spin up). If you see something like:\n",
    "```\n",
    "[2020-12-03 21:39:00] INFO - dask-saturn | Cluster is ready\n",
    "[2020-12-03 21:39:00] INFO - dask-saturn | Registering default plugins\n",
    "[2020-12-03 21:39:01] INFO - dask-saturn | {'tcp://10.0.0.150:35343': {'status': 'OK'}, 'tcp://10.0.24.234:35189': {'status': 'OK'}, 'tcp://10.0.3.113:42823': {'status': 'OK'}}\n",
    "Hello, world!\n",
    "```\n",
    "as the output, you are ready to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a8a602982e8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mscheduler_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'medium'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mworker_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'p32xlarge'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.7/site-packages/dask_saturn/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_workers, cluster_url, worker_size, worker_is_spot, scheduler_size, nprocs, nthreads, scheduler_service_wait_timeout, autoclose, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnprocs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mnthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnthreads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0mscheduler_service_wait_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler_service_wait_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             )\n\u001b[1;32m    122\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/saturn/lib/python3.7/site-packages/dask_saturn/core.py\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, n_workers, worker_size, worker_is_spot, scheduler_size, nprocs, nthreads, scheduler_service_wait_timeout)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_get_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mwarnings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"warnings\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Forbidden"
     ]
    }
   ],
   "source": [
    "from dask_saturn import SaturnCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = SaturnCluster(\n",
    "    n_workers = 3, \n",
    "    scheduler_size = 'medium', \n",
    "    worker_size = 'p32xlarge',\n",
    "    nthreads = 8\n",
    ")\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(3)\n",
    "\n",
    "print('Hello, world!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working on GPU machines for this tutorial, we should check and make sure all our workers and this Jupyter instance have GPU resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.run(lambda: torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access data\n",
    "\n",
    "This workshop will be using the [Stanford Dogs Dataset]( http://vision.stanford.edu/aditya86/ImageNetDogs/), which we have made available on S3, as read-only. No AWS account is required for access. Run the following cell to list the available files in the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "s3.glob('s3://saturn-public-data/dogs/Images/*/*.jpg')[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Some code cells throughout the workshop notebooks will require input based on the concepts being introduced in the notebook. Some cells will have most of the code written out, but indicate places to be filled in. Others will be completely blank and will require you to write a few lines.\n",
    "\n",
    "Try your best to fill in appropriate code and get the cell to run.\n",
    "\n",
    "To check your work (or cheat), expand the cell immediately below it. Make sure to run your cell with the correct code or run the hidden cell, as subsequent cells may depend on it. Try it here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILL IN THE BLANKS ###\n",
    "\n",
    "def hello(name, x):\n",
    "    print(f\"Hello, {name}!\")\n",
    "    print(f\"Your result is: {x + 5}\")\n",
    "    \n",
    "my_name = <<< YOUR NAME HERE >>>\n",
    "hello(my_name, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def hello(name, x):\n",
    "    print(f\"Hello, {name}!\")\n",
    "    print(f\"Your result is: {x + 5}\")\n",
    "    \n",
    "my_name = \"Kip\"\n",
    "hello(my_name, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you feel comfortable with all that, then we can begin with [Notebook 2](02-dask-basics.ipynb)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.giphy.com/media/XZrOvaUvmsCYL31HIe/giphy.gif\" alt=\"go\" style=\"width: 200px;\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
