{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/saturn_logo.png\" width=\"300\" />\n",
    "\n",
    "# Monitoring Model Learning Performance\n",
    "\n",
    "Let's take a look at the results we get from running this exact workflow on a few different cluster sizes. You've been given the statistics results from real job runs in the repo. \n",
    "\n",
    "Copy the lines of code below, paste it into the terminal window, and run. This will decompress the statistics into your directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "cd ~/project/workshop-dask-pytorch/\n",
    "gzip -d < ~/project/workshop-dask-pytorch/stats_cache2.tar.gz | tar xvf -\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname, join\n",
    "import pandas as pd\n",
    "import os\n",
    "import typing\n",
    "import json\n",
    "from plotnine import *\n",
    "import plotnine\n",
    "import dateutil.parser\n",
    "import pandas as pd\n",
    "\n",
    "def parse_results(root):\n",
    "    workers_dir = join(root, 'worker')\n",
    "    workers = [int(x) for x in os.listdir(workers_dir)]\n",
    "    data = []\n",
    "    for w in workers:\n",
    "        worker_dir = join(root, 'worker', str(w))\n",
    "        worker_files = sorted(os.listdir(worker_dir))\n",
    "        for idx, file in enumerate(worker_files):\n",
    "            date_str = file.split('data-')[-1].split('.')[0]\n",
    "            fpath = join(worker_dir, file)\n",
    "            d = dict(\n",
    "                count=idx,\n",
    "            )\n",
    "            with open(fpath) as f:\n",
    "                d.update(json.load(f))\n",
    "            data.append(d)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_run(dictinput):\n",
    "    path, rtype, compute, size, lr, workers = dictinput\n",
    "    df = pd.DataFrame(parse_results(path))\n",
    "    cleaned = df[['count', 'loss', 'correct', 'sample']].groupby(['count', 'sample']).agg({'loss': ['mean', 'min', 'max'],'correct': ['mean', 'min', 'max']}).reset_index()\n",
    "    cleaned['type'], cleaned['compute'], cleaned['size'], cleaned['lr'], cleaned['workers'] = [rtype,compute, size, lr, workers]\n",
    "    return cleaned\n",
    "\n",
    "def process_run_epochs(dictinput):\n",
    "    path, rtype, compute, size, lr, workers = dictinput\n",
    "    df = pd.DataFrame(parse_results(path))\n",
    "    cleaned = df[['epoch', 'loss', 'correct', 'sample']].groupby(['epoch', 'sample']).agg({'loss': ['mean', 'min', 'max'],'correct': ['mean', 'min', 'max']}).reset_index()\n",
    "    cleaned['type'], cleaned['compute'], cleaned['size'], cleaned['lr'], cleaned['workers'] = [rtype,compute, size, lr, workers]\n",
    "    return cleaned\n",
    "\n",
    "looplist = [[\"./stats/parallel/pt8_4wk\",\"parallel-4worker\",\"parallel\",100,'adaptive_01', 4],\n",
    "            [\"./stats/parallel/pt8_10wk\",\"parallel-10worker\",\"parallel\",100,'adaptive_01', 10],\n",
    "            [\"./stats/parallel/pt8_7wk\",\"parallel-7worker\",\"parallel\",100,'adaptive_01', 7],\n",
    "            [\"./stats/singlenode/pt8\", \"single\",\"single\",100, 'adaptive_01', 1],\n",
    "           ]\n",
    "\n",
    "results = list(map(process_run, looplist))\n",
    "e_results = list(map(process_run_epochs, looplist))\n",
    "\n",
    "test4 = pd.concat(results, axis=0)\n",
    "etest4 = pd.concat(e_results, axis=0)\n",
    "\n",
    "etest4.columns = [''.join(col).strip() for col in etest4.columns.values]\n",
    "test4.columns = [''.join(col).strip() for col in test4.columns.values]\n",
    "\n",
    "plotnine.options.figure_size = (11,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test6 = test4.query('sample == \"train\"')\n",
    "(ggplot(test6, aes(x='count', y='correctmean', color = \"factor(workers)\", group = 'type'))\n",
    "        + facet_wrap(facets = (\"size\"), ncol=3, labeller='label_both')\n",
    "        + theme_bw()\n",
    "        + geom_line()\n",
    "        + xlim(0, 825)\n",
    "        + labs(title = 'Correct Predictions: Training', x=\"Iterations\", y=\"Mean Correct Preds/Batch (Max 100)\", color = \"Workers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(test6, aes(x='count', y='lossmean', color = \"factor(workers)\", group = 'type'))\n",
    "        + facet_wrap(facets = (\"size\"), ncol=3, labeller='label_both')\n",
    "        + theme_bw()\n",
    "        + geom_line()\n",
    "        + xlim(0, 825)\n",
    "        + labs(title = 'Loss Reduction: Training', x=\"Iterations\", y=\"Loss\", color = \"Workers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test6 = test4.query('sample == \"eval\"')\n",
    "(ggplot(test6, aes(x='count', y='correctmean', color = \"factor(workers)\", group = 'type'))\n",
    "        + facet_wrap(facets = (\"size\"), ncol=3, labeller='label_both')\n",
    "        + theme_bw()\n",
    "        + geom_line()\n",
    "        + xlim(0, 825)\n",
    "        + labs(title = 'Correct Predictions: Evaluation', x=\"Iterations\", y=\"Mean Correct Preds/Batch (Max 100)\", color = \"Workers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(test6, aes(x='count', y='lossmean', color = \"factor(workers)\", group = 'type'))\n",
    "        + facet_wrap(facets = (\"size\"), ncol=3, labeller='label_both')\n",
    "        + theme_bw()\n",
    "        + geom_line()\n",
    "        + xlim(0, 825)\n",
    "        + labs(title = 'Loss Reduction: Evaluation', x=\"Iterations\", y=\"Loss\", color = \"Workers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(test4, aes(x='count', y='lossmean', color = \"factor(type)\", group = 'type'))\n",
    "        + facet_grid('workers~lr+sample')\n",
    "        + theme_bw()\n",
    "        + geom_line()\n",
    "        + xlim(0, 825)\n",
    "        + ylim(0, 13)\n",
    "        + labs(title = 'Loss Reduction', x=\"Iterations\", y=\"Loss\", color = \"Run Type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(test4, aes(x='count', y='correctmean', color = \"factor(type)\", group = 'type'))\n",
    "        + facet_grid('workers~lr+sample')\n",
    "        + theme_bw()\n",
    "        + geom_line()\n",
    "        + xlim(0, 825)\n",
    "        + labs(title = 'Correct Predictions', x=\"Iterations\", y=\"Correct (Max 100)\", color = \"Run Type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
