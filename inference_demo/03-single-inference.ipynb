{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/saturn_logo.png\" width=\"300\" />\n",
    "\n",
    "# Baseline Inference\n",
    "\n",
    "This project will do inference: classify an image with the most accurate label our model can give it. We're using the [Stanford Dogs Dataset]( http://vision.stanford.edu/aditya86/ImageNetDogs/), so we're asking Resnet50 to give us the correct breed label. \n",
    "\n",
    "Before we go into parallelization of this tasks, let's do a quick single-thread version. Then, in [Notebook 4](04-parallel-inference.ipynb), we'll convert this to a parallelized task.\n",
    "\n",
    "### Set up file store\n",
    "\n",
    "Connect to our S3 bucket where the images are held."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "s3 = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model and labels for ResNet\n",
    "\n",
    "First, we connect to the S3 data store, where we will get one sample image, as well as the 1000-item ImageNet label dataset. This will allow us to turn the predictions from our model into human-interpretable strings.\n",
    "\n",
    "PyTorch has the companion library torchvision which gives us access to a number of handy tools, including copies of popular models like Resnet. You can learn more about the available models in [the torchvision documentation](https://pytorch.org/docs/stable/torchvision/models.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "with s3.open('s3://saturn-public-data/dogs/imagenet1000_clsidx_to_labels.txt') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image and design transform steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "with s3.open(\"s3://saturn-public-data/dogs/2-dog.jpg\", 'rb') as f:\n",
    "    img = Image.open(f).convert(\"RGB\")\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256), \n",
    "    transforms.CenterCrop(250), \n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "def classify_img(transform, img, model):\n",
    "    img_t = transform(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "    resnet.eval()\n",
    "    out = model(batch_t)\n",
    "    \n",
    "    _, indices = torch.sort(out, descending=True)\n",
    "    percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "    labelset = [(classes[idx], percentage[idx].item()) for idx in indices[0][:5]]\n",
    "    return to_pil(img_t), labelset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Key aspects of the function to pay attention to include:\n",
    "\n",
    "* `img_t = transform(img)` : we must run the transformation we defined above on every image before we try to classify it.\n",
    "* `batch_t = torch.unsqueeze(img_t, 0)` : this step reshapes our image tensors to allow the model to accept it.\n",
    "* `resnet.eval()` : When we download the model, it can either be in training or in evaluation mode. We need it in evaluation mode here, so that it can return the predicted labels to us without changing itself.\n",
    "* `out = model(batch_t)` : This step actually evaluates the images. We are using batches of images here, so many can be classified at once.\n",
    "\n",
    "### Results Processing\n",
    "* `_, indices = torch.sort(out, descending=True)` : Sorts the results, high score to low (gives us the most likely labels at the top).\n",
    "* `percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100` : Rescales the scores from the model to probabilities (returns probabilities of each label) .\n",
    "* `labelset = [(classes[idx], percentage[idx].item()) for idx in indices[0][:5]]` : Interprets the top five labels in human readable form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dogpic, labels = classify_img(transform, img, resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogpic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job, we have proved the basic task works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.giphy.com/media/Qw75aRmhdpEuntisgj/giphy.gif\" alt=\"success\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Moving to Parallel\n",
    "\n",
    "Our job with one image runs quite fast! However, if we want to classify all 20,000+ images in the the [Stanford Dogs Dataset]( http://vision.stanford.edu/aditya86/ImageNetDogs/), that's going to add up to real time. So, let's take a look at how we can do this so that images are not classified one at a time, but in a highly parallel way, in [Notebook 4](04-parallel-inference.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
